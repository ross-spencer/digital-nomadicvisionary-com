<?xml version="1.0" encoding="iso-8859-1"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">

<head>
   <link href="css/digital.css" rel="stylesheet" type="text/css"></link>
   <style type="text/css">
      <!--
      -->
   </style>
</head>
<body class="indy">
   
      <img class="indy" src="images/references.jpg"></img>
      <br></br>
      <div class="indy">
         Although the development of computers continued throughout the 40's and early 50's it was within laboratories belonging to governments and large corporations beginning to specialise in this area that the development occurred. The ideologies within these laboratories were not always necessarily far-seeing. IBM for example, saw the computer as a bulk-processing machine, continuously operating but with very little interactivity. If this trend had continued it could be quite feasible that the computer as we now know it would not exist. However as the development continued and new machines were created old machines were not discarded but given to certain universities and other academic institutions such as the Massachusetts Institute of Technology (MIT) in America, for study and teaching purposes.
         <br></br>
         Within the laboratories of this institution the world of hacking was born and from that epicentre the world of computing has never been the same since. The MIT hackers, and other institutions given the ability to access machines such as the TX-0, the PDP-1 and the PDP-6 began to interact with the machines producing new software, where compilers and programming languages and other software were not comprehensive enough these hackers designed new compilers, new programming languages and new software for ever increasing new purposes. These hackers started everything from scratch in terms of software creating mathematical routines, graphical routines, basic calculators, rudimentary games, and as there visions grew so did their projects including venturing into the realms of artificial intelligence and musical composition. The predictions made by Ada Lovelace were beginning to be realised. Hardware was not untouched either and where these hackers had the ability to improve on the circuits and components o          f machines they were given the opportunity to experiment and install their new components if it would prove to be advantageous to development. 
         <br></br>
         The culture grew and although it began to leave the institutions, the programmers that left the institutions began to form companies or spread the word in other colleges, and those who began to discover computers outside of academic life became part of the culture themselves. The late 60's and 70's saw the development of hardware, and saw the advent of the first personal computer. The desire to create a machine that could be used in the home for programming, and the friendly competition and cooperation that came about in pursuit of this goal saw the creation of many computers of varying capabilities that could be assembled at home and then used for various programming tasks. However the unprecedented arrival of the Apple Macintosh, created by Steve Wozniack one of the many hardware hackers in this age, signalled the arrival of the personal desktop computer.
         <br></br>
         The 80's saw the creation of the gaming culture, along with the development of home and business software applications. Hardware also improved and began to spread through to regular homes and businesses and started to become part of everyday lives. This trend has continued and is still growing in the 21st century.
         <br></br>
         Computing has become part of everyday culture, and it is a large part of our heritage and the worlds identity, but in the same way that it has become part of our culture, culture itself is beginning to take advantage of digital processes in a way that may never have been imagined before.
         <br></br>
         When the very first computer game was created on the machines in the MIT laboratories in the 50's we saw an example of modelling and simulation, an artificially intelligent opponent gave the application a method of automated movement around the board, however this could be hard coded. The very first applications taking advantage of the data storage capabilities of computers created a whole new world of data representation, and the first applications allowing users to type words and save the created document, created a new method for the storage and retrieval of the printed form. The first database, the first use of the Internet, the list goes on but each advent in terms of the computer revolution did not just create a solution for a specific problem, rather solutions could be taken and re-used if appropriate, or re-programmed into more practical forms. This has lead to the application of computers over many cultural areas new and old, each taking advantage of old methods, and spearheading development          and the innovation of new computing technologies.  
         <br></br>
         <ul class="l1">
            <li>Art History</li>
	    <li>History</li>
	    <li>Music</li>
	    <li>Information Management</li>
	    <li>Libraries</li>
	    <li>Museums</li>
	    <li>Records and Archives</li> 
	    <li>Architecture</li> 
	    <li>Archaeology</li>
         </ul>
         So out of two seemingly disparate areas, technology, and culture, there now exists a synergy between the two that hopefully will prove to be advantageous to each other as this relationship continues to evolve. As we move through this course we shall learn more about the technology and begin to see applications of computers within these varying subject areas, and how they can help one another in terms of further development, and exactly how this synergy between the two exists.
         <p class="signature" align="right">rs</p><br></br>
         <p class="spacer"></p>
         <p class="copy">&copy MMV</p>
      </div>


</body>
</html>